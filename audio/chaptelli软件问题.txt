chaptelli软件问题：
3.1、固件只含逻辑部分，不含命令词以及语音播报，是否可行？
可以。但是不建议这样用，这种应用建议采用通用芯片
3.2、1006剩余多少资源，可做什么？
SRAM：15k左右代码空间，SDRAM：3M左右。外设资源具体看手册。
3.3、不同命令词不同灵敏度（阈值）可以设置么；
可以设置，具体咨询开发人员。
3.4、命令词的长度，命令词最大支持多少：
1、建议4-6个词，相对来说识别率比较好，误识别也比较少。太长可能用户没办法一句话讲完
2、命令次的编辑距离要适当大些，减少误识别。
3、相似韵母发音避免使用，例如：书房/厨房，风干/烘干
4、选择比较好发音的字，例如：普通的“普”发音很难大声。
5、减少太口语化及生活中使用频次太高的词。例如“我”开头的词
6、命令词不是越多越好，终端客户能记住的命令词有限，建议有规律的使用精简核心词。
7、 命令词个数，可以支持300词条。
3.5、串口0为啥要短接？
串口0短接URAT0_TX为高电平，则进入SRAM启动的调试模式，以及用于烧录固件,不短接的话则直接从spi flash启动，如果是串口烧写代码的话不需要短接。
3.6、客户的音响类产品，如何在音响播放的同时进行识别，以便在播放音乐的同时可以打断及识别。
可以支持，需要使用双mic方案，用20921的AEC功能进行设置。
3.7、DSP降噪算法是哪家的
20921是科胜讯的；我司的相关算法开发中。
3.8、可以提供一个样例源码么？希望了解开发难度
可以，可以提供整套SDK，需要商务确定好及签DNA
3.9、请问CI1006开发板这个是android系统吗？
不是SOC+APP形态，是ASIC硬逻辑+cortexM4形态。
3.10、我们需要二次开发来实现远场唤醒、语音识别？
不需要
3.11、CI1006可以通过I2C接收codec ADC后的数据吗？
不行，须通过II2S接口处理数据
3.12、唤醒词能支持到多少个，命令词最大数量？
命令词可支持300个，命令词多少唤醒就多少个，但是不建议这么做，因为唤醒词多了，误唤醒率高。
3.13、模块我们可以二次开发么？我们是否可以修改语音识别指令？
可以二次开。命令词可以更改，但是目前需要在我们公司的服务器上进行训练。即贵司可以提供命令词，我司帮你们做固件。
3.14、程序运行流程 flash-sram？
把程序从flash加载到sram后进行运行。
3.15、录音和识别使用音频文件的区别
数据采集的录音板：PCM，16k，16bit双声道/WAV,16k.16bit双声道
识别的音频：格式PCM，采样频率16k，采样位数16bit单声道
3.16、远场拾音是否有特殊处理
没有
3.17、1006是否支持麦克风阵列
Mic阵支持与1006没关系，看dsp芯片。
3.18、SDK里面有没有用到芯片56脚 TEST 信号，为高进入测试模式？
该IO请严格按照CI给出的标准线路图进行画pcb （layout）。
3.19、SDK是否可以配置成工厂测试模式，I/O口测试？
目前邮票版有这个功能，每个案子可能要根据具体情况修改这部分代码。
3.20、代码能不能控制声音增益？
可以，控制codec的声音输出。ES8388（8374）还是8002功放？
3.21、设备工作在某些状态会有噪声，有没有针对这个情况的优化？
需要录音进行分析和优化
3.22、打印没出现“VAD[0]”这样的信息就进入低功耗模式了？
不是，进入低功耗有相应的的打印，“进入低功耗”
3.23、void vad_state_lib(int flag) 这个函数是在哪里调用的？
在lib库里被调用的。
3.24、special words是什么功能？什么情况下添加到special word里面？
Special word主要是用于对容易误识别的词特殊处理，如果A命令词容易误识别成B命令词，可以把B加入到specialword。
3.25、简单介绍下如何配置I/O口，SPI、I2C、I2S、UART的使用
参考代码
3.26、你们芯片识别后的是输出文本还是字符串？
可以输出命令词的index，也可以输出字符串，建议使用index。
3.27、flash里存的是训练后的模型吗，你们是如何做训练的？
Flash内存的内容包括训练的模型和命令词模型，需要客户提供命令词，我们便可以很快生成命令词模型。详细的训练过程包括数据录音采集，切分校对，数据处理，数据训练，模型测试等过程。
3.28、唤醒词是否可以多设定几个，唤醒时长是否可调整？
唤醒词可以设定多个，但是不建议设置太多，容易导致误唤醒。唤醒时长可以调整，也不建议设置太长，唤醒时间太长可能容易误识别。
3.29、能否加入多个模块建立局域网实现智能家居联动？类似方案是否做过？
目前未实现该功能开发、技术上没问题，具体看客户这边规划，CI可以提供技术支持。
3.30、你们这个模块断电后，是否会丢失工作状态？
模块可以保存数据到spi flash，这样断电再上电不会丢失这些数据。软件实现。
3.31、你们本地语音识别的反应速度是多少？
200-800ms,噪声环境中或者词条过多的时候，反应有可能会稍微慢些
3.32、你们和其他本地语音识别上有什么区别
我司语音识别采用DNN硬件进行海量命令词识别，识别速度快，识别率高，成本低，功耗低。
新塘：早期的高斯算法，通过对比声音特性进行训练和识别，关键词必须是固定词，识别率有上限，词条个数20以下。
CI  DNN算法：基于神经网络的深度学习算法，提取声音特征进训练，关键词允许一定的模糊性，识别率理论最高99%，词条300以内。
3.33、你们的唤醒词反应比较快速，而命令词有些不灵敏，这个是怎样的情况？是只对唤醒词敏感吗?
跟命令词和说话人的发音有关，所以命令词选择好了，体验就会好很多
3.34、sdk如何配置单双麦？
user_config.h里面的宏配置USE_ASR8388 (0:双麦，1：单麦)
3.35、sdk如何配置串口？
目前常用的通信串口是uart1/uart2，user_config.h里面有两个宏，UART2_ENABLE和UART2_USEUART1_ENABLE，需要使用uart2时把宏UART2_ENABLE设置为1；需要使用uart1时把宏UART2_ENABLE和UART2_USEUART1_ENABLE都设置为1；
3.36、固件如何合成？
首先通过IAR工具编译生成user_bin用户代码文件(\fw_updata\img\user),然后打开fw_updata\tools\下的打包工具FW Merge Tool_V2.12.exe文件选择fw_config.ini配置文件（含有\img路径下存放的bootloader，\attachment下存放的语音唤醒词、命令词、数据模型、声音文件），确认配置信息正确后，点击生成对应的固件fw_config.bin，该文件是需要烧录进SPI的固件。
3.37、MXIC的SPI Flash(型号MX25L6406EM2I-12G)不支持串口升级。
问题描述：用J-LINK升级固件，能够运行正常。采用串口升级固件，升级后固件无法运行(bootloader1.0.4)。
原因分析：BOOTLOADER会根据文件占用空间大小，采用64K块、32K块、4K扇区的不同的擦除操作。经过擦除测试（见下图）及查询MX25L6406EM2I-12G数据手册，发现只
支持64K块4K扇区操作，不支持32K块擦除操作，32K擦除产生异常(会多擦除数据)。而语音模块的BOOTLOADER采用32k块擦除，所以导致固件升级异常。
解决办法：
(1)如果用MXIC的SPI Flash需要修改bootloader；
(2)采用GigaDevice或华邦SPI FLASH(均支持64K块，32K块,4K操作)。

3.38、音频文件如何生成？有什么要求？
播报音可以通过开放的语音合成平台合成，如科大讯飞或者百度。音频文件要求为16KHz采样率，单声道，16bit。
3.39、可否自定义唤醒词？
目前正在开发，尚不支持。
3.40、timer如何使用？
目前可用的timer为timer0，需要先初始化timer0中断和使能，然后调用TIMx_us设置定时器，timer_stop停止定时器。
3.41、中英文sdk有区别吗？
现在中英文sdk进行了合并优化，不需要区分。使用英文时需要在task_asr.c文件里，void MacroInit(void)函数里，调用macro_asr_init函数参数tag设置为“-”。
3.42、可以中英文混合吗？
暂时不支持中英文混合识别，可以做双语方案，即通过某条指令切换为中英文。
3.43、识别词条与响应词条开放不?
识别命令词暂不开发，响应的声音部分实际就是些wav，客户可以自己录制使用
3.44、在拿到芯片后，我们希望对300首歌曲做音乐推荐识别，在进行数据训练时，训练的样本是歌曲的名字还是用户说歌名的声音？可以简单介绍一下你们的DNN训练和测试流程么？
歌曲名字（文字）or  歌曲名字（声音）------>训练------>词库/用户输入（声音）------>语音识别（声音转文字）------>测试（输入的歌曲与词库匹配）------>播放歌曲
3.45、若只使用I2S1而不使用I2S0，也不能将I2S0关掉，若关掉I2S0则会导致I2S1也不能用，因为I2S0与I2S1两路I2S共用MCLK：

3.46、代码中ASR_BEAM宏的理解
将其理解为并行的赛车赛道，数值越大表示赛道越多，当声音进来后，根据权重决定是否将其放入赛道:
1、当命令词越多的时候，需要越多赛道才能容纳更多的赛车（命令词），有的命令词初始的权重不够，导致进入不了赛道，则不会有最终结果；
2、赛道越多，对系统的资源占用越大，负担重了，整体的解码速度下降，识别受vad影响导致体验下降；
3、如果产品的逻辑存在某些状态只响应部分命令词的情况，则可以将这部分命令词独立做个模型，这时，赛道足够，每个词初始可能都可以分到一个赛道，这样最终的阈值可能能达到预期；
4、范围9.0~10.0，数值越大，负担越重，因为影响很多东西，所以一般不调。